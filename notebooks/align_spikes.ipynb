{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed for the tutorial\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "#from AdaBandFlt import *\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>El 21</th>\n",
       "      <th>El 31</th>\n",
       "      <th>El 41</th>\n",
       "      <th>El 22</th>\n",
       "      <th>El 32</th>\n",
       "      <th>El 42</th>\n",
       "      <th>El 23</th>\n",
       "      <th>El 33</th>\n",
       "      <th>El 43</th>\n",
       "      <th>El 15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%t</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>-2.61</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>4.09</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>-3.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>2.61</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>-2.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.14</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>3.52</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>-3.07</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>-2.39</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.48</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.80</th>\n",
       "      <td>2.05</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.84</th>\n",
       "      <td>3.64</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.88</th>\n",
       "      <td>4.89</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.92</th>\n",
       "      <td>3.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.96</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>-4.89</td>\n",
       "      <td>-3.98</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               El 21         El 31         El 41         El 22         \\\n",
       "%t                                                                      \n",
       "0.00                  -2.61          1.02          0.80          1.93   \n",
       "0.04                  -3.30          0.00          2.05          1.25   \n",
       "0.08                  -2.73          0.11          2.73          1.48   \n",
       "0.12                  -3.07         -0.45          1.25          0.80   \n",
       "0.16                  -2.39          1.48          0.34          1.14   \n",
       "...                     ...           ...           ...           ...   \n",
       "20799.80               2.05         -4.43          2.95          0.11   \n",
       "20799.84               3.64         -5.68         -0.80         -1.70   \n",
       "20799.88               4.89         -3.41         -3.30         -1.59   \n",
       "20799.92               3.07          0.00         -1.82         -1.48   \n",
       "20799.96               0.45          0.00         -3.64         -3.18   \n",
       "\n",
       "               El 32         El 42         El 23         El 33         \\\n",
       "%t                                                                      \n",
       "0.00                  -1.25         -1.59         -0.57          4.09   \n",
       "0.04                  -1.02         -0.45         -1.82          2.61   \n",
       "0.08                   0.45          1.14         -1.14          3.52   \n",
       "0.12                  -0.57         -0.57         -1.25          2.50   \n",
       "0.16                   0.00         -0.57         -0.34          1.48   \n",
       "...                     ...           ...           ...           ...   \n",
       "20799.80               2.39          3.86         -2.27          2.61   \n",
       "20799.84               2.73          0.91         -1.70          0.23   \n",
       "20799.88               0.57         -1.70         -1.82         -0.34   \n",
       "20799.92              -1.14         -3.30         -2.73         -0.34   \n",
       "20799.96              -3.75         -5.68         -4.89         -3.98   \n",
       "\n",
       "               El 43         El 15         \n",
       "%t                                         \n",
       "0.00                  -1.14         -0.34  \n",
       "0.04                  -0.45         -0.80  \n",
       "0.08                  -0.23         -0.80  \n",
       "0.12                  -1.02         -0.57  \n",
       "0.16                  -0.23          0.45  \n",
       "...                     ...           ...  \n",
       "20799.80               2.95          0.34  \n",
       "20799.84               1.59          1.14  \n",
       "20799.88              -0.11          1.25  \n",
       "20799.92              -1.25          0.57  \n",
       "20799.96              -2.73         -0.34  \n",
       "\n",
       "[520000 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "#Location = r'/Users/33614/ExternalDrive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/D_Drive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'\n",
    "\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_new_spike_data/539W6cbaseRaw.txt'\n",
    "\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_valid_window(window, test_level = 5):\n",
    "    \"\"\"\n",
    "    window : the window in the signal that has to be tested\n",
    "    \n",
    "    This funtion test the window to insure that it doesn't contain the signal of interest (spike)\n",
    "    \"\"\"\n",
    "    #non zero ?\n",
    "    second = np.percentile(window, 2)\n",
    "    thirtyth = np.percentile(window, 30)\n",
    "    #print(str(second) + \"\\t\" + str(thirtyth) + \"\\t\" + str(second/thirtyth))\n",
    "    if abs(second/thirtyth) < test_level : \n",
    "        return True\n",
    "    else : \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_noise_levels(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = \"RMS\",\n",
    "                      percentile_value = 25):\n",
    "    \n",
    "    if estimator_type == \"RMS\":\n",
    "        return init_noise_levels_RMS(signal, fs, \n",
    "                      noise_window_size = noise_window_size,\n",
    "                      required_valid_windows = required_valid_windows,\n",
    "                      old_noise_level_propagation = old_noise_level_propagation, \n",
    "                      test_level = test_level,\n",
    "                      percentile_value = percentile_value)\n",
    "        \n",
    "    elif estimator_type == \"MAD\":\n",
    "        return init_noise_levels_MAD(signal, fs, \n",
    "                      noise_window_size = noise_window_size,\n",
    "                      required_valid_windows = required_valid_windows,\n",
    "                      old_noise_level_propagation = old_noise_level_propagation, \n",
    "                      test_level = test_level,\n",
    "                      percentile_value = percentile_value)\n",
    "    \n",
    "    else: return None\n",
    "    \n",
    "    \n",
    "def init_noise_levels_RMS(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      percentile_value = 25):\n",
    "    \n",
    "    nb_valid_windows = 0\n",
    "    list_RMS = []\n",
    "    noise_levels = []\n",
    "    \n",
    "    noise_level = -1\n",
    "    \n",
    "     \n",
    "    #boucle en indice\n",
    "#    for window_index in range(0,len(signal)-(len(signal)%int(fs*noise_window_size)),int(fs*noise_window_size)):\n",
    "    for window_index in range(0,len(signal),int(fs*noise_window_size)):\n",
    "        test = test_valid_window(signal.iloc[window_index: window_index + int(fs*noise_window_size)], test_level)\n",
    "        if nb_valid_windows < required_valid_windows:\n",
    "            if test == True :\n",
    "                RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                list_RMS.append(RMS)\n",
    "                nb_valid_windows += 1\n",
    "            \n",
    "            if nb_valid_windows == required_valid_windows:\n",
    "                noise_level = np.percentile(list_RMS, percentile_value)\n",
    "                for elm in range(0, window_index, int(fs*noise_window_size)):\n",
    "                    noise_levels.append(noise_level)\n",
    "                \n",
    "        else :\n",
    "            \"\"\"if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window:]), 25)\n",
    "                else :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window: window + int(fs*noise_window_size)]), 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\"\"\"\n",
    "            if test == True:\n",
    "                if (window_index + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    RMS = np.sqrt(np.mean(signal.iloc[window_index:]**2))\n",
    "                else :\n",
    "                    RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                list_RMS.append(RMS)\n",
    "                NX = np.percentile(list_RMS, percentile_value)\n",
    "                new_noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*NX\n",
    "                noise_level = new_noise_level\n",
    "            noise_levels.append(noise_level)\n",
    "            \n",
    "    #cas ou il n'y a pas eut 100 fenetres de bruit valides rencontrees\n",
    "    if noise_level == -1:\n",
    "        \n",
    "        #cas ou aucune fenetre valide n'a ete rencontree\n",
    "        if noise_levels == []:\n",
    "            for elm in range(0, len(signal), int(fs*noise_window_size)):\n",
    "                noise_levels.append(0)\n",
    "            \n",
    "        else:\n",
    "            noise_level = np.percentile(list_RMS, percentile_value)\n",
    "            for elm in range(0, len(signal), int(fs*noise_window_size)):\n",
    "                noise_levels.append(noise_level)\n",
    "        \n",
    "    \n",
    "    noise_levels.append(noise_level)        \n",
    "    plt.figure()\n",
    "    plt.plot(list_RMS)\n",
    "    plt.xlabel('Time Windows')\n",
    "    plt.title('RMS values')\n",
    "    plt.grid(True)\n",
    "                \n",
    "    return noise_levels\n",
    "\n",
    "def init_noise_levels_MAD(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      percentile_value = 25):\n",
    "    \n",
    "    nb_valid_windows = 0\n",
    "    list_MAD = []\n",
    "    noise_levels = []\n",
    "     \n",
    "    #boucle en indice\n",
    "    for window_index in range(0,len(signal),int(fs*noise_window_size)):\n",
    "        test = test_valid_window(signal.iloc[window_index: window_index + int(fs*noise_window_size)], test_level)\n",
    "        if nb_valid_windows < required_valid_windows:\n",
    "            if test == True :\n",
    "                ###RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                MAD = scipy.stats.median_absolute_deviation(signal.iloc[window_index: window_index + int(fs*noise_window_size)])\n",
    "                list_MAD.append(MAD)\n",
    "                nb_valid_windows += 1\n",
    "            \n",
    "            if nb_valid_windows == required_valid_windows:\n",
    "                noise_level = np.percentile(list_MAD, percentile_value)\n",
    "                for elm in range(0, window_index, int(fs*noise_window_size)):\n",
    "                    noise_levels.append(noise_level)\n",
    "                \n",
    "        else :\n",
    "            \"\"\"if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window:]), 25)\n",
    "                else :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window: window + int(fs*noise_window_size)]), 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\"\"\"\n",
    "            if test == True:\n",
    "                if (window_index + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    ###RMS = np.sqrt(np.mean(signal.iloc[window_index:]**2))\n",
    "                    MAD = scipy.stats.median_absolute_deviation(signal.iloc[window_index:])\n",
    "                else :\n",
    "                    ###RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                    MAD = scipy.stats.median_absolute_deviation(signal.iloc[window_index: window_index + int(fs*noise_window_size)])\n",
    "                list_MAD.append(MAD)\n",
    "                NX = np.percentile(list_MAD, percentile_value)\n",
    "                new_noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*NX\n",
    "                noise_level = new_noise_level\n",
    "            noise_levels.append(noise_level)\n",
    "    \n",
    "    noise_levels.append(noise_levels)        \n",
    "    plt.figure()\n",
    "    plt.plot(list_MAD)\n",
    "    plt.xlabel('Time Windows')\n",
    "    plt.title('MAD values')\n",
    "    plt.grid(True)\n",
    "                \n",
    "    return noise_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find spikes\n",
    "\n",
    "def find_spike(signal, initial_index, noise_levels, fs, spike_info,\n",
    "               window_size = 0.002,\n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 3.5,\n",
    "               maxseparation = 0.0008,\n",
    "               time_checkmaxlocal = 0.0002,\n",
    "               reduct_factor = 0.6): #facteur de rÃ©duction pour le threshold positif\n",
    "    \n",
    "    offset_index = int(np.round(signal.index[0]*fs/1000))\n",
    "    \n",
    "    if initial_index < len(signal) + offset_index:\n",
    "        i = initial_index\n",
    "        for value in signal.iloc[initial_index-offset_index:]:\n",
    "            threshold = threshold_factor*noise_levels[int(np.round((i/fs)//noise_window_size))]\n",
    "            if value < -threshold:\n",
    "\n",
    "                #verifier qu'on est pas encore dans un effet du spike precedant et decaler la fenetre si besoin\n",
    "                if signal.iloc[initial_index-offset_index-1] < -threshold:\n",
    "                    for value_ in signal.iloc[initial_index-offset_index:]:\n",
    "                        if value_ > -threshold:\n",
    "                            return i\n",
    "                        i += 1\n",
    "\n",
    "                indice_1er_depass = i\n",
    "                while(True):\n",
    "                    if i < len(signal)+offset_index-1:\n",
    "                        if signal.iloc[i-offset_index + 1]>signal.iloc[i-offset_index]:\n",
    "                            break\n",
    "                        else :\n",
    "                            i+=1\n",
    "                    else :\n",
    "                        break\n",
    "                             \n",
    "                #partir Ã  la recherche d'un max du spike a droite\n",
    "                i_max_right = 'nan'  \n",
    "                for k in range(int(np.round(maxseparation*fs))):\n",
    "                    if (i-offset_index + k) < len(signal)-1:\n",
    "                        if signal.iloc[i-offset_index+k] > reduct_factor*threshold and signal.iloc[i-offset_index+k]>signal.iloc[i-offset_index+k+1]:\n",
    "                            if checkmaxlocal(signal, \"right\",i+k,offset_index,int(np.round(time_checkmaxlocal*fs))):\n",
    "                                i_max_right = i+k\n",
    "                                break\n",
    "                #partir Ã  la recherche d'un max du spike a gauche\n",
    "                i_max_left = 'nan'  \n",
    "                for k in range(int(np.round(maxseparation*fs))):\n",
    "                    if (i-offset_index - k) > 0:\n",
    "                        if signal.iloc[i-offset_index-k] > reduct_factor*threshold and signal.iloc[i-offset_index-k]>signal.iloc[i-offset_index-k-1]:\n",
    "                            if checkmaxlocal(signal, \"left\",i-k,offset_index,int(np.round(time_checkmaxlocal*fs))):\n",
    "                                i_max_left = i-k\n",
    "                                break\n",
    "                \n",
    "                \n",
    "                if i_max_left == 'nan' and i_max_right == 'nan':\n",
    "                    #on a pas rencontrÃ© de spike\n",
    "                    while signal.iloc[i-offset_index] < -threshold:\n",
    "                        i += 1\n",
    "                    return i\n",
    "                \n",
    "                else:\n",
    "                    #rÃ©colte infos du spike\n",
    "                    amplitude = 0\n",
    "                    if i_max_left != 'nan' and i_max_right != 'nan':\n",
    "                        if signal.iloc[i_max_left-offset_index] < signal.iloc[i_max_right-offset_index]:\n",
    "                            amplitude = signal.iloc[i_max_right-offset_index] - signal.iloc[i-offset_index]\n",
    "                        else :\n",
    "                            amplitude = signal.iloc[i_max_left-offset_index] - signal.iloc[i-offset_index]\n",
    "                    elif i_max_left != 'nan':\n",
    "                            amplitude = signal.iloc[i_max_left-offset_index] - signal.iloc[i-offset_index]\n",
    "                    elif i_max_right != 'nan':\n",
    "                            amplitude = signal.iloc[i_max_right-offset_index] - signal.iloc[i-offset_index]\n",
    "                    \n",
    "                        # indice min, indice 1er depasssement\n",
    "                        # max gauche, max droite\n",
    "                        # variation d'amplitude entre min et max\n",
    "                    \n",
    "                    spike_info.append([i, indice_1er_depass,\n",
    "                                        i_max_left, i_max_right,\n",
    "                                        amplitude])\n",
    "                    return indice_1er_depass+int(np.round(window_size*fs))\n",
    "                \n",
    "                break  \n",
    "            i += 1\n",
    "\n",
    "    return -44\n",
    "\n",
    "def checkmaxlocal(local_signal, sens, supposed_i_min,offset_index, nb_index_research=3):\n",
    "    if(sens == \"right\"):\n",
    "        k = 0\n",
    "        while k <= nb_index_research:\n",
    "        #for k in range(nb_index_research):\n",
    "            if((local_signal.iloc[supposed_i_min-offset_index + k]) < (local_signal.iloc[supposed_i_min-offset_index + k + 1])):\n",
    "                return False\n",
    "            k += 1\n",
    "        return True\n",
    "    elif(sens == \"left\"):\n",
    "        k = 0\n",
    "        while k <= nb_index_research:\n",
    "        #for k in range(nb_index_research):\n",
    "            if((local_signal.iloc[supposed_i_min-offset_index - k]) < (local_signal.iloc[supposed_i_min-offset_index - k - 1])):\n",
    "                return False\n",
    "            k+=1\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_spikes(signal, noise_levels, fs,\n",
    "               window_size = 0.002,\n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 3.5,\n",
    "               maxseparation = 0.0008,\n",
    "               time_checkmaxlocal = 0.0002,\n",
    "               reduct_factor = 0.6):\n",
    "    \n",
    "    initial = int(np.round(signal.index[0]*fs/1000))\n",
    "    spike_info = []\n",
    "    \n",
    "    while initial != -44:\n",
    "        initial = find_spike(signal, initial, noise_levels, fs, spike_info,\n",
    "                             window_size = window_size,\n",
    "                             noise_window_size = noise_window_size,\n",
    "                             threshold_factor = threshold_factor,\n",
    "                             maxseparation = maxseparation,\n",
    "                             time_checkmaxlocal = time_checkmaxlocal,\n",
    "                             reduct_factor = reduct_factor)\n",
    "        \n",
    "    df_spike_info = pd.DataFrame(spike_info)\n",
    "    df_spike_info.columns = ['indice_min', 'indice_1er_depass','indice_max_gauche','indice_max_droite','Delta_amplitudes']\n",
    "\n",
    "    return df_spike_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record spike\n",
    "\n",
    "def record_spikes(signal, fs, spike_info,\n",
    "                  align_method,\n",
    "                  t_before = 0.002,\n",
    "                  t_after = 0.002):\n",
    "    \n",
    "    if (align_method in spike_info.columns) == False:\n",
    "        print(\"align_method is incorrect, please choose one of the following :\" + str(spike_info.columns))\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        spike_centers = spike_info[align_method].values\n",
    "        \n",
    "    t_b = int(np.round(fs*(t_before)))\n",
    "    t_a = int(np.round(fs*(t_after)))\n",
    "    \n",
    "    data = np.array([[float(x) for x in range(t_b+t_a+1)]])\n",
    "    \n",
    "    initial_index = int(np.round(signal.index[0]*fs/1000))\n",
    "    \n",
    "    for center in spike_centers:\n",
    "        if center < t_b + initial_index:\n",
    "            spike = [0 for i in range(0, t_b-(center-initial_index))]\n",
    "            spike = np.concatenate((spike, signal.values[:center + t_a - initial_index]))\n",
    "            data = np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        elif center > len(signal)-t_a + initial_index:\n",
    "            spike = signal.values[center - t_b - initial_index:]\n",
    "            spike = np.concatenate((spike,[0 for i in range(0, t_a - (len(signal) + initial_index-center))]))\n",
    "            data = np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        else :\n",
    "            spike = signal.values[center - t_b - initial_index: center + t_a + 1 - initial_index]\n",
    "            data = np.insert(data, len(data), spike, axis=0)\n",
    "\n",
    "    print(np.shape(data))\n",
    "    data = data.transpose()\n",
    "    spike_data = pd.DataFrame(data)\n",
    "    \n",
    "    return spike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_spikes_oneline(signal, fs, spike_info,\n",
    "                  align_method,\n",
    "                  t_before = 0.001,\n",
    "                  t_after = 0.002):\n",
    "\n",
    "    if (align_method in spike_info.columns) == False:\n",
    "        print(\"align_method is incorrect, please choose one of the following :\" + str(spike_info.columns))\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        spike_centers = spike_info[align_method].values\n",
    "        \n",
    "    offset_index = int(np.round(signal.index[0]*fs/1000))\n",
    "    \n",
    "    t_b = int(np.round(fs*(t_before)))\n",
    "    t_a = int(np.round(fs*(t_after)))\n",
    "    \n",
    "    data = np.array(['NaN' for x in range(len(signal))])\n",
    "    data = data.astype(float)\n",
    "    times = np.array(['NaN' for x in range(len(signal))])\n",
    "    times = times.astype(pd.Timestamp)\n",
    "    \n",
    "    for center in spike_centers:\n",
    "        if center < t_b + offset_index:\n",
    "            data[:center + t_a - offset_index] = signal.values[:center + t_a - offset_index]\n",
    "            times[:center + t_a - offset_index] = signal.index[:center + t_a - offset_index]\n",
    "            \n",
    "        elif center > len(signal) - t_a + offset_index:\n",
    "            data[center - t_b - offset_index:] = signal.values[center - t_b - offset_index:]\n",
    "            times[center - t_b - offset_index:] = signal.index[center - t_b - offset_index:]\n",
    "            \n",
    "        else :\n",
    "            data[center - t_b - offset_index: center + t_a + 1 - offset_index] = signal.values[center - t_b - offset_index: center + t_a + 1 - offset_index]\n",
    "            times[center - t_b - offset_index: center + t_a + 1 - offset_index] = signal.index[center - t_b - offset_index: center + t_a + 1 - offset_index]\n",
    "\n",
    "    spike_data_oneline = pd.DataFrame(data, index = times.astype(float))\n",
    "    \n",
    "    return spike_data_oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint_spikes(spike_data,\\n             t_before_alignement = 0.0015,\\n             first_spike = 1,\\n             last_spike = 20,\\n             fs = 25000,\\n             y_lim_min = -50,\\n             y_lim_max = 60)\\n             \\nprint_spikes(spike_data,\\n             t_before_alignement = 0.0015,\\n             fs = 25000,\\n             randomize = True,\\n             nb_spike = 20,\\n             y_lim_min = -50,\\n             y_lim_max = 60)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def print_spikes(spike_data,\n",
    "                 t_before_alignement = 0,\n",
    "                 first_spike = 1,\n",
    "                 last_spike = -1,\n",
    "                 fs = 25000,\n",
    "                 randomize = False,\n",
    "                 nb_spike = 20,\n",
    "                 y_lim_min = -50,\n",
    "                 y_lim_max = 60):\n",
    "    \n",
    "    if randomize == True:        \n",
    "        kept = []\n",
    "        m = len(spike_data.values[0])\n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = spike_data.iloc[:,kept].values\n",
    "        \n",
    "    else:\n",
    "        x = spike_data.iloc[:,first_spike:last_spike]\n",
    "        \n",
    "    figure = plt.figure()\n",
    "    t_b = int(np.round(fs*(t_before_alignement)))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    axes.plot((spike_data.iloc[:,0]-t_b)*1000/fs, x)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "    \n",
    "\"\"\"\n",
    "print_spikes(spike_data,\n",
    "             t_before_alignement = 0.0015,\n",
    "             first_spike = 1,\n",
    "             last_spike = 20,\n",
    "             fs = 25000,\n",
    "             y_lim_min = -50,\n",
    "             y_lim_max = 60)\n",
    "             \n",
    "print_spikes(spike_data,\n",
    "             t_before_alignement = 0.0015,\n",
    "             fs = 25000,\n",
    "             randomize = True,\n",
    "             nb_spike = 20,\n",
    "             y_lim_min = -50,\n",
    "             y_lim_max = 60)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_spikes_burst_distinction(signal, fs, spike_info,\n",
    "                  align_method,\n",
    "                  t_before = 0.002,\n",
    "                  t_after = 0.002):\n",
    "    \n",
    "    spike_data_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == True], align_method, t_before = t_before, t_after = t_after)\n",
    "    spike_data_no_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == False], align_method, t_before = t_before, t_after = t_after)\n",
    "    \n",
    "    return spike_data_burst, spike_data_no_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_spikes_oneline_distinction(signal, fs, spike_info,\n",
    "                  align_method,\n",
    "                  t_before = 0.001,\n",
    "                  t_after = 0.002):\n",
    "    \n",
    "    spike_data_oneline_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == True], align_method, t_before = t_before, t_after = t_after)\n",
    "    spike_data_oneline_no_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == False], align_method, t_before = t_before, t_after = t_after)\n",
    "    \n",
    "    return spike_data_oneline_burst, spike_data_oneline_no_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "####  BANK OF PARTS OF DATA\n",
    "\n",
    "all_raw_data = df #Entire recording from all electrodes\n",
    "\n",
    "full_signal = df.iloc[:,1] #Entire recording from electrode 58\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Sample rate and desired cutoff frequencies (in Hz).\n",
    "fs = 25000.0\n",
    "lowcut = 100.0\n",
    "highcut = 2500.0\n",
    "\n",
    "\n",
    "y = butter_bandpass_filter(df.iloc[:,1], lowcut, highcut, fs, order=6)\n",
    "\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index[:1000000]\n",
    "\n",
    "signal_filtered = filtereddf.iloc[:,0] #Entire recording filtered by bandpass, for one electrode\n",
    "\n",
    "###########################\n",
    "## Signal de 20s\n",
    "\n",
    "xminspike = int(np.round(12548*(fs/1000)))\n",
    "xmaxspike = int(np.round(13000*(fs/1000)))\n",
    "\n",
    "burst_data = filtereddf.iloc[xminspike:xmaxspike,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "####   TEST ADABANDFLT AVEC SIGNAL ORIGINAL (PASSE-BANDE+WIENER)\n",
    "\n",
    "# Choices:\n",
    "#  - full_signal : entire signal from first electrode\n",
    "#  - signal_filtered : entire signal from first electrode after bandpass\n",
    "#  - noise_data : part of signal where only noise (after bandpass)\n",
    "#  - burst_data : part of signal where burst (after bandpass)\n",
    "\n",
    "\n",
    "part_of_signal = signal_filtered\n",
    "\n",
    "signal = part_of_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING SIGNAL:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df.index, signal, 'g-', linewidth=2, label='data filtered')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Amplitude [ÂµV]')\n",
    "plt.title('Filtered Signal')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 20,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = \"RMS\",\n",
    "                      percentile_value = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noise Levels')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(noise_levels)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Noise Amplitude [ÂµV]')\n",
    "plt.title('Noise Levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice_min</th>\n",
       "      <th>indice_1er_depass</th>\n",
       "      <th>indice_max_gauche</th>\n",
       "      <th>indice_max_droite</th>\n",
       "      <th>Delta_amplitudes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2241</td>\n",
       "      <td>2241</td>\n",
       "      <td>nan</td>\n",
       "      <td>2253</td>\n",
       "      <td>11.429386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7125</td>\n",
       "      <td>7125</td>\n",
       "      <td>7083</td>\n",
       "      <td>nan</td>\n",
       "      <td>11.753287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9632</td>\n",
       "      <td>9630</td>\n",
       "      <td>nan</td>\n",
       "      <td>9653</td>\n",
       "      <td>14.984720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14975</td>\n",
       "      <td>14975</td>\n",
       "      <td>nan</td>\n",
       "      <td>14994</td>\n",
       "      <td>12.571033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16221</td>\n",
       "      <td>16220</td>\n",
       "      <td>nan</td>\n",
       "      <td>16259</td>\n",
       "      <td>13.463169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>486675</td>\n",
       "      <td>486674</td>\n",
       "      <td>486633</td>\n",
       "      <td>nan</td>\n",
       "      <td>12.601039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>493403</td>\n",
       "      <td>493402</td>\n",
       "      <td>493377</td>\n",
       "      <td>493412</td>\n",
       "      <td>12.225191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>512271</td>\n",
       "      <td>512270</td>\n",
       "      <td>nan</td>\n",
       "      <td>512281</td>\n",
       "      <td>12.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>513835</td>\n",
       "      <td>513835</td>\n",
       "      <td>513803</td>\n",
       "      <td>nan</td>\n",
       "      <td>11.536016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>517075</td>\n",
       "      <td>517075</td>\n",
       "      <td>nan</td>\n",
       "      <td>517085</td>\n",
       "      <td>11.807490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indice_min  indice_1er_depass indice_max_gauche indice_max_droite  \\\n",
       "0          2241               2241               nan              2253   \n",
       "1          7125               7125              7083               nan   \n",
       "2          9632               9630               nan              9653   \n",
       "3         14975              14975               nan             14994   \n",
       "4         16221              16220               nan             16259   \n",
       "..          ...                ...               ...               ...   \n",
       "819      486675             486674            486633               nan   \n",
       "820      493403             493402            493377            493412   \n",
       "821      512271             512270               nan            512281   \n",
       "822      513835             513835            513803               nan   \n",
       "823      517075             517075               nan            517085   \n",
       "\n",
       "     Delta_amplitudes  \n",
       "0           11.429386  \n",
       "1           11.753287  \n",
       "2           14.984720  \n",
       "3           12.571033  \n",
       "4           13.463169  \n",
       "..                ...  \n",
       "819         12.601039  \n",
       "820         12.225191  \n",
       "821         12.000984  \n",
       "822         11.536016  \n",
       "823         11.807490  \n",
       "\n",
       "[824 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs, \n",
    "                          window_size = 0.001, \n",
    "                          noise_window_size = 0.01,\n",
    "                          threshold_factor = 3.5,\n",
    "                          maxseparation = 0.002,\n",
    "                          reduct_factor = 0.6)\n",
    "\n",
    "spike_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 101)\n"
     ]
    }
   ],
   "source": [
    "spike_data = record_spikes(signal, fs, spike_info,\n",
    "                  'indice_1er_depass',\n",
    "                  t_before = 0.002,\n",
    "                  t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline = record_spikes_oneline(signal, fs, spike_info,\n",
    "                  'indice_1er_depass',\n",
    "                  t_before = 0.002,\n",
    "                  t_after = 0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spike_data_oneline = record_spikes_oneline(signal, fs, spike_info,\n",
    "                  'indice_zero_central',\n",
    "                  t_before = 0.002,\n",
    "                  t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(df.index, signal, color = 'blue')\n",
    "plt.plot(spike_data_oneline.index, spike_data_oneline, color = 'red')\n",
    "plt.title('Filtered Signal with Detected Spikes with RMS')\n",
    "plt.xlabel('Time Windows')\n",
    "plt.ylabel('Amplitude [ÂµV]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "print_spikes(spike_data,\n",
    "             t_before_alignement = 0.002,\n",
    "             first_spike = 1,\n",
    "             last_spike = 40,\n",
    "             fs = 25000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
